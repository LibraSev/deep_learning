{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3,4])\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249700.75030671962\n",
      "vector: 0.9980201721191406ms\n",
      "249700.7503067112\n",
      "loop: 498.66604804992676ms\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "a = np.random.rand(1000000)\n",
    "b = np.random.rand(1000000)\n",
    "\n",
    "tic = time.time()\n",
    "c = np.dot(a,b)\n",
    "toc = time.time()\n",
    "\n",
    "print(c)\n",
    "print(\"vector: \"+str(1000*(toc-tic))+\"ms\")\n",
    "\n",
    "c=0\n",
    "tic=time.time()\n",
    "for i in range(1000000):\n",
    "    c+=a[i]*b[i]\n",
    "toc=time.time()\n",
    "print(c)\n",
    "print(\"loop: \"+str(1000*(toc-tic))+\"ms\")\n",
    "\n",
    "#向量化的好处"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "u=np.exp(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    v = tf.get_variable(\n",
    "    \"v\",initializer = tf.zeros_initializer()(shape=[1]))\n",
    "    \n",
    "\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    v = tf.get_variable(\n",
    "    \"v\",initializer = tf.ones_initializer()(shape=[1]))\n",
    "    \n",
    "with tf.Session(graph=g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\",reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "\n",
    "\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\",reuse=True):\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_2:0\", shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g=tf.Graph()\n",
    "a=tf.constant([1.0,2.0],name=\"a\")\n",
    "b=tf.constant([2.0,3.0],name=\"b\")\n",
    "\n",
    "result =tf.add(a,b,name=\"add\")\n",
    "#result = a+b \n",
    "print (result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_8:0\", shape=(2,), dtype=float32)\n",
      "[3. 5.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "a=tf.constant([1.0,2.0],name=\"a\")\n",
    "b=tf.constant([2.0,3.0],name=\"b\")\n",
    "\n",
    "result = a + b\n",
    "print (result)\n",
    "sess = tf.Session()\n",
    "print(sess.run(result))\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.6523422]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1))\n",
    "\n",
    "x=tf.placeholder(tf.float32,shape=(1,2),name=\"input\")\n",
    "a=tf.matmul(x,w1)\n",
    "y=tf.matmul(a,w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.initialize_all_variables()\n",
    "sess.run(init_op)\n",
    "\n",
    "#print(sess.run(y))\n",
    "\n",
    "print(sess.run(y,feed_dict={x:[[0.7,0.9]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578]]\n"
     ]
    }
   ],
   "source": [
    "#向前传播过程1\n",
    "import tensorflow as tf\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "x=tf.constant([[0.7,0.9]])\n",
    "\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "sess.run(w1.initializer)\n",
    "sess.run(w2.initializer)\n",
    "\n",
    "print(sess.run(y))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.957578]]\n"
     ]
    }
   ],
   "source": [
    "#向前传播过程2\n",
    "import tensorflow as tf\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "x=tf.constant([[0.7,0.9]])\n",
    "\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init_op = tf.global_variables_initializer()#便捷的变量初始化\n",
    "sess.run(init_op)\n",
    "\n",
    "print(sess.run(y))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2749494 ]\n",
      " [0.43409672]\n",
      " [1.0565504 ]]\n"
     ]
    }
   ],
   "source": [
    "#向前传播过程3\n",
    "import tensorflow as tf\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(3,2), name=\"input\")\n",
    "\n",
    "\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "init_op = tf.global_variables_initializer()#便捷的变量初始化\n",
    "sess.run(init_op)\n",
    "\n",
    "print(sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]}))\n",
    "#通过变量x替代常量x，需提供x的取值\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.8113182   1.4845988   0.06532937]\n",
      " [-2.4427042   0.0992484   0.5912243 ]]\n",
      "[[-0.8113182 ]\n",
      " [ 1.4845988 ]\n",
      " [ 0.06532937]]\n",
      "after 0 training steps,cross entropy on all data is 0.0674925\n",
      "after 1000 training steps,cross entropy on all data is 0.0163385\n",
      "after 2000 training steps,cross entropy on all data is 0.00907547\n",
      "after 3000 training steps,cross entropy on all data is 0.00714436\n",
      "after 4000 training steps,cross entropy on all data is 0.00578471\n",
      "[[-1.9618275  2.582354   1.6820377]\n",
      " [-3.4681718  1.0698231  2.11789  ]]\n",
      "[[-1.824715 ]\n",
      " [ 2.6854665]\n",
      " [ 1.418195 ]]\n"
     ]
    }
   ],
   "source": [
    "#完整神经网络样例\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "w1=tf.Variable(tf.random_normal([2,3],stddev=1,seed=1))\n",
    "w2=tf.Variable(tf.random_normal([3,1],stddev=1,seed=1))\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None,2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None,1), name='y-input')\n",
    "#\n",
    "a = tf.matmul(x,w1)\n",
    "y = tf.matmul(a,w2)\n",
    "#\n",
    "cross_entropy = -tf.reduce_mean(\n",
    "    y_*tf.log(tf.clip_by_value(y,1e-10,1.0)))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "Y = [[int(x1+x2<1)]for(x1,x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "    print (sess.run(w1))\n",
    "    print (sess.run(w2))\n",
    "            \n",
    "\n",
    "    STEPS=5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size)%dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        \n",
    "        sess.run(train_step,\n",
    "                 feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "        if i %1000 ==0:\n",
    "            total_cross_entropy = sess.run(\n",
    "                cross_entropy,feed_dict={x:X,y_:Y})\n",
    "            print(\"after %d training steps,cross entropy on all data is %g\"%(i,total_cross_entropy))\n",
    "            \n",
    "    print (sess.run(w1))\n",
    "    print (sess.run(w2))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True]\n",
      "[4. 3. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v1 = tf.constant([1.0, 2.0, 3.0, 4.0])\n",
    "v2 = tf.constant([4.0, 3.0, 2.0, 1.0])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "print (tf.greater(v1,v2).eval())\n",
    "print (tf.where(tf.greater(v1,v2),v1,v2).eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0193471]\n",
      " [1.0428091]]\n"
     ]
    }
   ],
   "source": [
    "#自定义损失函数\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from numpy.random import RandomState\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None,2), name='x-input')\n",
    "y_ = tf.placeholder(tf.float32, shape=(None,1), name='y-input')\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([2,1],stddev=1,seed=1))\n",
    "y = tf.matmul(x,w1)\n",
    "#\n",
    "\n",
    "\n",
    "loss_less = 10\n",
    "loss_more = 1\n",
    "loss = tf.reduce_sum(tf.where(tf.greater(y,y_),\n",
    "                             (y-y_)*loss_more,\n",
    "                             (y_-y)*loss_less))\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "\n",
    "rdm = RandomState(1)\n",
    "dataset_size = 128\n",
    "X = rdm.rand(dataset_size,2)\n",
    "Y = [[x1+x2+rdm.rand()/10.0-0.05]for(x1,x2) in X]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op=tf.initialize_all_variables()\n",
    "    sess.run(init_op)\n",
    "   \n",
    "    STEPS=5000\n",
    "    for i in range(STEPS):\n",
    "        start = (i*batch_size)%dataset_size\n",
    "        end = min(start+batch_size,dataset_size)\n",
    "        \n",
    "        sess.run(train_step,\n",
    "                 feed_dict={x:X[start:end],y_:Y[start:end]})\n",
    "\n",
    "    print (sess.run(w1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
